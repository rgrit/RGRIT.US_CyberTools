
# üöÄ **RGRIT CyberTools** üî•  
**The Ultimate Cybersecurity Toolkit** ‚Äì Built for **Hackers, Defenders, and Cyber Warriors**.  

# Disclaimer

**Educational & Research Purposes Only**  
Everything in this repository is provided solely for educational and research purposes. The demos, scripts, and materials are intended to demonstrate security practices and generative AI (GenAI) skills in a lawful, ethical, and responsible manner.

**Ethical & Legal Use**  
All content is designed for users to explore and learn. It is your responsibility to ensure that any use of these materials complies with all applicable laws, regulations, and ethical standards. This repository does not endorse or encourage any malicious or unauthorized activities.

**AI-Generated Content**  
Approximately **99%** of the content in this repository has been generated using advanced AI tools. This reflects the significant role that generative AI plays in the creation of these materials, showcasing modern capabilities in the field.

**No Warranty**  
The content is provided "as-is," without any warranty‚Äîexpress or implied. The authors are not responsible for any misuse or consequences arising from the use of this material.

By using this repository, you agree to the above terms and acknowledge that you are solely responsible for ensuring the ethical and legal application of the information provided.  
üîó **[Explore the Repo](https://github.com/rgrit/RGRIT.US_CyberTools)**  

## Recent Updates (as of 2025-03-12)
- üÜï **Added** `Auto_Documetation/auto_readme.py`
- ‚ùå **Removed** `Auto_Documetation/test.py`
- ‚úèÔ∏è **Updated** `Ansible/Purple_Team_Lab_Infra_As_Code/deploy_vms.yml`
- ‚úèÔ∏è **Updated** `Ansible/Purple_Team_Lab_Infra_As_Code/download-proxmox-isos.yml`
- ‚úèÔ∏è **Updated** `Ansible/Purple_Team_Lab_Infra_As_Code/hosts.yml`
- ‚úèÔ∏è **Updated** `Ansible/Purple_Team_Lab_Infra_As_Code/proxmox-initial-setup.yml`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/Email/email_generate_sigma.py`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/Email/email_grab_attachments.py`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/Email/email_list_senders.py`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/Email/email_overview.py`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/Email/email_security_report.py`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/Secure_Code_Review/scan_for_credentials.py`
- ‚úèÔ∏è **Updated** `Blue_Team_Scripts/file_integrity_monitoring/file_integrity_monitor.py`
- ‚úèÔ∏è **Updated** `Custom_Sigma_Rules/correlation_lnx_syslog_flipper_badusb_repeated_enumeration.yml`
- ‚úèÔ∏è **Updated** `Custom_Sigma_Rules/lnx_syslog_flipper_badusb_identifiers.yml`
- ‚úèÔ∏è **Updated** `Custom_Sigma_Rules/lnx_syslog_flipper_badusb_inconsistent_branding.yml`
- ‚úèÔ∏è **Updated** `Ducky_Scripts/convert_to_ducky.py`
- ‚úèÔ∏è **Updated** `Elastic/check_cluster_healthy.py`
- ‚úèÔ∏è **Updated** `Malware_Analysis/virusTotalAPI/virus_total_scan.py`
- ‚úèÔ∏è **Updated** `Network_Security/network_monitoring/sniffer.py`
- ‚úèÔ∏è **Updated** `Network_Security/wireless_security/WiFi_Discover/wifi_packet_sniff.py`
- ‚úèÔ∏è **Updated** `Network_Security/wireless_security/WiFi_Discover/wifi_signal_discovery.py`
- ‚úèÔ∏è **Updated** `Network_Security/wireless_security/Wifi_Attack/wifi_deauth.py`
- ‚úèÔ∏è **Updated** `Network_Security/wireless_security/Wifi_Attack/wifi_jam.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_mgmt_csv_to_OPML.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/analysis/text_analysis.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/analysis/threat_analysis.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/config.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/heatmap_generator.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/main.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/reporting/report_generator.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/api_utils.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/file_utils.py`
- ‚úèÔ∏è **Updated** `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/rss_utils.py`

## Repository Overview
Below is an overview of all Python and YAML scripts organized by the second-level directory:

### üìÅ `CTI_and_Detection/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_mgmt_csv_to_OPML.py` | This Python script converts a CSV file ("Awesome Threat Intel Blogs - MASTER.csv") into an OPML (Outline Processor Markup Language) file ('feeds.opml'). It reads blog names and feed links from the CSV, creating XML outlines for each valid entry, then writes these as RSS feeds in the OPML format. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_mgmt_csv_to_OPML.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/analysis/text_analysis.py` | This Python function, `summarize_article`, uses an API (ollama) to generate a 5-7 sentence summary of an article. It emphasizes cybersecurity or threat-hunting angles if relevant, focusing on IoCs and TTPs for detection engineering insights. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/analysis/text_analysis.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/analysis/threat_analysis.py` | This Python script defines several functions to assist in cybersecurity analysis, particularly in the context of threat detection and response using the Sigma tool. Here's a brief overview of each function:  1. `suggest_sigma_tags`: This function generates suggested Sigma tags based on the provided summary text and optional additional analysis details. It follows the Sigma Tag Specification (Version 2.1.0) guidelines, including namespaces like attack, car, cve, d3fend, detection, and stp (Summiting the Pyramid). The function returns a formatted list of suggested tags with brief explanations.  2. `generate_detection_story`: This function creates a 'detection story' that includes context, assumptions, detection approach, evaluation, and limitations for a given scenario. It uses the summary text as input to generate these sections, providing a structured narrative for threat detection and response.  3. `suggest_sigma_tags`: Although there's a function with this name twice in the provided code snippet, they appear to be identical. This function generates suggested Sigma tags based on the observed threat behavior or detection scenario, along with any known mappings to MITRE ATT&CK, MITRE D3FEND, CVEs, or the MITRE Cyber Analytics Repository (CAR). It returns a formatted list of suggested tags with brief explanations, following the Sigma Tag Specification guidelines.  4. `generate_detection_story`: This function creates a 'detection story' that includes context, assumptions, detection approach, evaluation, and limitations for a given scenario. It uses the summary text as input to generate these sections, providing a structured narrative for threat detection and response.  5. `suggest_sigma_tags`: This function generates suggested Sigma tags based on the provided summary text and optional additional analysis details. It follows the Sigma Tag Specification (Version 2.1.0) guidelines, including namespaces like attack, car, cve, d3fend, detection, and stp (Summiting the Pyramid). The function returns a formatted list of suggested tags with brief explanations.  6. `suggest_mitre_tags`: This function suggests MITRE ATT&CK tags based on the provided summary text and optional additional analysis details. It returns a formatted list of suggested tags with brief explanations, following MITRE's tagging guidelines. However, this function is not defined in the provided code snippet.  7. `suggest_mitre_d3fend_tags`: This function suggests MITRE D3FEND tags based on the provided summary text and optional additional analysis details. It returns a formatted list of suggested tags with brief explanations, following MITRE's D3FEND tagging guidelines. However, this function is not defined in the provided code snippet.  8. `suggest_cve_tags`: This function suggests CVE tags based on the provided summary text and optional additional analysis details. It returns a formatted list of suggested tags with brief explanations, following CVE's tagging guidelines. However, this function is not defined in the provided code snippet.  9. `suggest_car_tags`: This function suggests CAR (MITRE Cyber Analytics Repository) tags based on the provided summary text and optional additional analysis details. It returns a formatted list of suggested tags with brief explanations, following CAR's tagging guidelines. However, this function is not defined in the provided code snippet.  These functions aim to streamline the process of creating detection rules and threat intelligence by suggesting relevant tags and providing structured narratives for threat detection and response scenarios. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/analysis/threat_analysis.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/config.py` | This Python script configures settings for an email security report system, including RSS feed (RSS_URL), API endpoints (OLLAMA_API_URL), and model name (MODEL_NAME). It also defines file paths for processed articles (PROCESSED_ARTICLES_FILE) and output directory (OUTPUT_DIR). Time variables 'now' and 'yesterday' are set using datetime and timedelta. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/config.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/heatmap_generator.py` | This Python script scrapes MITRE tactics and techniques from markdown files in a specified directory. It counts occurrences of these codes (e.g., TA0001, T1202) using regex patterns, then generates an ATT&CK Navigator heatmap JSON file with the counts for visualization purposes. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/heatmap_generator.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/main.py` | This Python script fetches, analyzes, and generates reports on threat intelligence articles from an RSS feed. It summarizes articles, identifies threats, extracts Indicators of Compromise (IoCs), assesses Sigma rule feasibility, suggests Sigma tags, and generates detection stories. Processed articles are stored to avoid reprocessing. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/main.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/reporting/report_generator.py` | This is a Python script designed to generate Markdown reports for threat intelligence articles. The script includes functions for sanitizing filenames and creating individual or multiple reports.  The `sanitize_filename` function removes non-alphanumeric characters from the filename and replaces spaces with underscores, making it suitable for use in file paths.  The `create_individual_report` function generates a single Markdown report for a given threat intelligence article. It writes the report to a file with a name based on the sanitized title and the current date. The report includes sections for a summary of the article, detected indicators of compromise (IoCs), Sigma rule feasibility and recommended tags, and a detection story (if available).  The `create_multiple_reports` function is similar to `create_individual_report`, but it processes a list of articles instead of a single article. This allows for the generation of multiple reports in one go.  Both functions use the current date in the format 'Month Day, Year' and write the reports with UTF-8 encoding. They also print a message indicating the file path where each report has been saved.  The script assumes that certain keys are present in the input article dictionary, such as 'title', 'link', 'summary', 'iocs', 'sigma_assessment', and 'detection_story' (with nested keys like 'Context', 'Assumptions', 'Detection Approach', 'Evaluation', and 'Limitations'). If these keys or their respective sub-keys are not present in the input data, the corresponding sections may not appear in the generated report. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/reporting/report_generator.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/api_utils.py` | This Python function, `call_ollama_api_with_retry`, sends a POST request to the LLaMA API with retry logic. It takes a prompt, retries (default 3), and delay (default 5 seconds) as inputs. The function attempts to send the prompt to the specified model, handling potential exceptions and re-trying up to the defined number of times before giving up. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/api_utils.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/file_utils.py` | This Python script includes functions to load and save sets of processed article IDs in JSON format. It handles potential errors like file not found or invalid JSON. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/file_utils.py) |
| `OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/rss_utils.py` | 140-char description: This Python script fetches and parses an RSS feed using `feedparser`. It handles exceptions for failed requests, returning an empty list on failure. Success returns parsed feed entries as a list. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/OSINT_Scripts/CTI_and_Detection/rss_feed_to_detection/utils/rss_utils.py) |

### üìÅ `Email/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Blue_Team_Scripts/Email/email_generate_sigma.py` | This Python script processes email security reports (.md files) in the "email_reports" directory to extract metadata and IoCs. It then sends this data to a language model for threat analysis, generates Sigma rules, and saves them in the "sigma_rules" directory. The script utilizes regex patterns for IoC extraction and JSON parsing for metadata. It supports various log sources including Office 365, Sysmon, Firewall, and Email Security Gateway logs. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/Email/email_generate_sigma.py) |
| `Blue_Team_Scripts/Email/email_grab_attachments.py` | This Python script scans a Thunderbird profile directory for email mailbox files, allows user selection of a mailbox, and extracts email attachments. It saves these attachments in a specified directory, then generates a Markdown report listing extracted attachments with metadata. The report includes file type, size, and a summary of extensions used. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/Email/email_grab_attachments.py) |
| `Blue_Team_Scripts/Email/email_list_senders.py` | This Python script scans Thunderbird's IMAP profile for mailbox files, allowing user selection of a folder to analyze. It then extracts and reports the email senders' list along with their occurrence counts in a markdown file named "email_senders_list.md". | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/Email/email_list_senders.py) |
| `Blue_Team_Scripts/Email/email_overview.py` | This Python script scans a Thunderbird email profile, extracts emails, and uses an LLM (Language Learning Model) to assess immediate action requirements. It lists available mailboxes, allows user selection, then generates a Markdown report detailing each email's analysis. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/Email/email_overview.py) |
| `Blue_Team_Scripts/Email/email_security_report.py` | This Python script scans a Thunderbird mail profile for email folders, extracts metadata from emails, and uses Ollama to analyze potential security threats. It generates markdown reports detailing extracted data and LLM analysis. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/Email/email_security_report.py) |

### üìÅ `Purple_Team_Lab_Infra_As_Code/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Ansible/Purple_Team_Lab_Infra_As_Code/deploy_vms.yml` | This Ansible playbook creates three Proxmox VMs with specified configurations (CPU cores, RAM, storage). VMs named 'kali-linux', 'wazuh-ubuntu', and 'purple-lab' are to be installed from respective ISO files. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Ansible/Purple_Team_Lab_Infra_As_Code/deploy_vms.yml) |
| `Ansible/Purple_Team_Lab_Infra_As_Code/download-proxmox-isos.yml` | This Ansible playbook downloads specified ISOs to Proxmox ISO storage, ensuring the directory exists and setting appropriate permissions. It downloads Kali Linux 2024.4, Ubuntu 22.04.5 Server, Security Onion 2.4.130, TrueNAS SCALE 24.10.2, DragonOS FocalX R37.1, and Ubuntu Studio 24.04.2 ISOs. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Ansible/Purple_Team_Lab_Infra_As_Code/download-proxmox-isos.yml) |
| `Ansible/Purple_Team_Lab_Infra_As_Code/hosts.yml` | This Ansible playbook configuration targets a Proxmox server (192.168.1.175), using root as the user and SSH key for authentication. It also sets up API credentials for interaction with Proxmox, disabling certificate validation for security reasons. Replace "<<APIKEY>>>" with actual token secret. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Ansible/Purple_Team_Lab_Infra_As_Code/hosts.yml) |
| `Ansible/Purple_Team_Lab_Infra_As_Code/proxmox-initial-setup.yml` | This Ansible playbook configures a Proxmox server, disabling enterprise repositories and setting up NIC passthrough. It removes all references to enterprise.proxmox.com from apt sources, enables the non-enterprise repository, installs necessary packages, configures IOMMU for PCIe passthrough, identifies physical network interfaces, binds them to VFIO driver, and adds them to all VMs. Optionally, it can reboot the server after configuration changes. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Ansible/Purple_Team_Lab_Infra_As_Code/proxmox-initial-setup.yml) |

### üìÅ `Secure_Code_Review/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Blue_Team_Scripts/Secure_Code_Review/scan_for_credentials.py` | This Python script scans a specified directory for .py files, excluding certain directories like ".venv", ".env", etc. It uses Ollama LLM to analyze each file for hardcoded sensitive information (API keys, passwords). Results are saved as Markdown reports in "security_reports" folder, along with secure coding recommendations. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/Secure_Code_Review/scan_for_credentials.py) |

### üìÅ `auto_readme.py/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Auto_Documetation/auto_readme.py` | This is a Python script designed to generate a detailed README file for a repository containing cybersecurity tools. The script performs several tasks:  1. **Categorizing Files**: It organizes Python and YAML files into directories based on the second level of their path.  2. **Generating Descriptions**: For each file, it attempts to generate a description using an AI model (not specified in the provided code). If unsuccessful, it defaults to an empty string.  3. **Creating Recent Updates Section**: It identifies added, removed, and updated files since the last run and formats them as a list under "Recent Updates."  4. **Building README Content**: The script constructs the README file in Markdown format, including a disclaimer section, recent updates, and a categorized listing of all scripts with their names, descriptions, and links to GitHub.  5. **Saving the README and Tracking Changes**: Finally, it saves the generated README to the `docs/` directory within the repository and updates a history file to keep track of current descriptions for future comparisons.  The script ensures that the repository is presented in an organized manner, facilitating easy exploration and understanding of its contents for educational or research purposes. It emphasizes ethical use and responsible application of the tools provided, disclaiming any misuse or consequences arising from their employment. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Auto_Documetation/auto_readme.py) |

### üìÅ `check_cluster_healthy.py/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Elastic/check_cluster_healthy.py` | This Python script initializes an Elasticsearch client using provided credentials and a CA certificate. It attempts to fetch the cluster's health status, printing it or error details if connection fails. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Elastic/check_cluster_healthy.py) |

### üìÅ `convert_to_ducky.py/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Ducky_Scripts/convert_to_ducky.py` | This Python script checks for a 'duckencoder.jar' in "RGRIT.US/Ducky_Scripts", lists all .txt Ducky Scripts, then encodes each .txt to .bin using the jar. It prints success or error messages for each file and concludes with a summary of processed scripts. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Ducky_Scripts/convert_to_ducky.py) |

### üìÅ `correlation_lnx_syslog_flipper_badusb_repeated_enumeration.yml/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Custom_Sigma_Rules/correlation_lnx_syslog_flipper_badusb_repeated_enumeration.yml` | This correlation rule, titled "Correlation - Flipper Zero BadUSB Repeated Insertion Events," monitors USB device insertion events flagged by a specific detection rule. It identifies three or more such events within 5 minutes on the same host, possibly indicating unauthorized or automated BadUSB activity using a Flipper Zero device. False positives include rapid plug/unplug events during hardware testing or maintenance. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Custom_Sigma_Rules/correlation_lnx_syslog_flipper_badusb_repeated_enumeration.yml) |

### üìÅ `file_integrity_monitoring/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Blue_Team_Scripts/file_integrity_monitoring/file_integrity_monitor.py` | This is a Python script for a graphical user interface (GUI) application using the Tkinter library, along with additional modules like `glob`, `filedialog`, `scrolledtext`, and `ttk` from Tkinter's themed widgets. The application is designed to manage file integrity checks with baselines. Here's a brief overview of its components:  1. **GUI Layout**:    - The main window contains various elements, including text areas for verbose output (`self.output_text`), buttons for creating baselines and checking integrity (`baseline_button`, `check_button`), and a history table (`self.history_tree`) using Treeview.    - There's also a scrolled text area for displaying detailed logs.  2. **Directory Selection**:    - The `select_directory` method allows users to choose a directory, which is then displayed in the GUI.  3. **Baseline Management**:    - Baseline files (JSON format) are managed through radio buttons in the `baseline_radio_frame`.    - New baselines can be added with the `add_baseline_radio` method when a file is created.  4. **Integration Checks**:    - The `handle_check` method, triggered by clicking the "Check Integrity" button, performs integrity checks based on selected or default baseline files.  5. **Logging and Displaying Information**:    - A `log` method is used to append messages to the verbose output text area (`self.output_text`).  6. **Additional Functionality**:    - The script includes methods for loading existing baselines from the directory, setting a default baseline if none are selected, and displaying history changes using a Treeview widget.  The provided code snippets are incomplete, so this description is based on the visible parts of the script. To fully understand its functionality, you would need the complete code. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Blue_Team_Scripts/file_integrity_monitoring/file_integrity_monitor.py) |

### üìÅ `lnx_syslog_flipper_badusb_identifiers.yml/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Custom_Sigma_Rules/lnx_syslog_flipper_badusb_identifiers.yml` | This Linux-based tool detects suspicious Flipper Zero BadUSB device insertion events, targeting unusual vendor ID "1234:ABCD", manufacturer "Brain Actuated Technologies", and device type "Generic USB Keyboard". High alert level due to potential hardware attack risks. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Custom_Sigma_Rules/lnx_syslog_flipper_badusb_identifiers.yml) |

### üìÅ `lnx_syslog_flipper_badusb_inconsistent_branding.yml/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Custom_Sigma_Rules/lnx_syslog_flipper_badusb_inconsistent_branding.yml` | Title: Flipper Zero BadUSB Inconsistency Detection  This rule identifies Linux syslog entries where a USB device is branded as "Brain Actuated Technologies" but registered as "Generic USB Keyboard". This discrepancy suggests the device may be masquerading as harmless peripherals, indicative of potential BadUSB attacks, particularly involving Flipper Zero devices. High-severity alert due to its implications for hardware security and deception tactics. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Custom_Sigma_Rules/lnx_syslog_flipper_badusb_inconsistent_branding.yml) |

### üìÅ `network_monitoring/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Network_Security/network_monitoring/sniffer.py` | This is a Python script designed for network traffic analysis and intrusion detection. It captures and analyzes network packets using the Scapy library. The script performs various checks on captured packets to identify unusual or suspicious activities, such as:  1. High proportion of encrypted traffic (SSL/TLS/SSH) 2. Fragmented packets, which could indicate a fragmentation attack or evasion technique 3. Concentration of traffic from a single IP address, potentially indicating a targeted attack or misconfiguration 4. Low local traffic compared to external traffic, which might suggest an external attack 5. Unusual protocols (other than TCP, UDP, ICMP) being used 6. High number of ARP requests or responses 7. Excessive TCP SYN or FIN packets 8. HTTP GET and POST requests from unusual sources or in unusual volumes 9. DNS response packets from unexpected sources 10. Packets larger or smaller than typical sizes, which could indicate malicious activities like data exfiltration or denial-of-service attacks  The script also logs the summary of extended metrics, such as the total number of TCP, UDP, and ICMP packets, HTTP requests, DNS responses, and encrypted packets. It saves captured packets to a PCAP file for further analysis. The progress bar function updates the countdown label and displays the progress percentage during packet capture.  The script assumes that certain variables (e.g., `log_callback`, `pcap_filename`, and `capture_running`) are defined elsewhere in the code or passed as arguments to this function. It also relies on external libraries like Scapy, time, and tkinter for network packet manipulation, time tracking, and graphical user interface elements, respectively. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Network_Security/network_monitoring/sniffer.py) |

### üìÅ `virusTotalAPI/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Malware_Analysis/virusTotalAPI/virus_total_scan.py` | This Python script reads IOCs (Indicators of Compromise) from a CSV file and queries VirusTotal using an API key to check for malware signatures. It flags suspicious IOCs, saving the results in another CSV file, including last analysis date and malicious count. It respects VirusTotal's free tier rate limit by sleeping for 15 seconds between queries. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Malware_Analysis/virusTotalAPI/virus_total_scan.py) |

### üìÅ `wireless_security/` Directory
| üìÑ **Script Name** | **Description** | **Link** |
| ----------------- | --------------- | -------- |
| `Network_Security/wireless_security/WiFi_Discover/wifi_packet_sniff.py` | This Python script is designed to capture and analyze WiFi packets to gather information about nearby networks, including their SSIDs, BSSIDs (MAC addresses), channels, encryption types, average signal strengths, and connected clients. It uses the `scapy` library for packet sniffing and analysis.  Here's a breakdown of the script's functionality:  1. **Packet Capture**: The script sets up a network interface in promiscuous mode to capture all WiFi packets within range. It then continuously captures packets for a specified duration (`CAPTURE_DURATION`).  2. **Packet Analysis**: For each captured packet, the script performs the following analyses:    - **Management Frames (Mgmt)**: Analyzes management frames to extract SSID, BSSID, channel, and encryption type.    - **Data Frames**: Analyzes data frames to determine signal strength (RSSI) for connected clients.  3. **Network Discovery**: The script maintains a dictionary (`discovered_networks`) that stores information about each discovered network, including:    - SSID    - BSSID    - Channel    - Encryption type    - Average signal strengths    - List of connected clients  4. **Client Detection**: The script identifies client connections by analyzing the source and destination MAC addresses in data frames. If a client is associated with a known BSSID, its MAC address is added to the list of clients for that network.  5. **Report Generation**: After capturing packets for the specified duration, the script generates a Markdown-formatted report summarizing the discovered networks and their relevant information. The report includes:    - Total number of captured packets    - Counts of management, control, and data frames    - List of discovered networks with details such as SSID, BSSID, channel, encryption type, average signal strength, and connected clients  6. **Next Steps**: For each discovered network, the script generates example commands for potential attacks (e.g., deauthentication or jamming) using hypothetical helper scripts (`wifi_deauth.py` and `wifi_jam.py`). These commands are included in a separate section of the report for reference.  To run this script, ensure you have the required libraries installed: ```bash pip install scapy ```  You'll also need to have appropriate permissions to capture WiFi packets on your system. On Linux, this typically involves running the script as root or using `sudo`. Additionally, make sure your wireless network interface is available and correctly identified by the script (e.g., "wlan0" or "wifi0").  Here's an example of how to run the script: ```bash sudo python3 wifi_packet_sniffer.py --duration 60 ```  This command captures WiFi packets for 60 seconds and generates a report in Markdown format. Adjust the duration as needed for your use case. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Network_Security/wireless_security/WiFi_Discover/wifi_packet_sniff.py) |
| `Network_Security/wireless_security/WiFi_Discover/wifi_signal_discovery.py` | The provided Python script performs the following tasks related to wireless network analysis:  1. **WiFi Scanning**: The `scan_wifi()` function scans for available Wi-Fi networks and their signal strengths using platform-specific APIs (e.g., `netifaces` for Linux). It categorizes networks based on their signal strength into "Strong," "Good," or "Weak."  2. **Visualization**: The `plot_wifi()` function generates a horizontal bar chart of the scanned Wi-Fi networks, displaying their SSIDs and corresponding signal strengths. The generated image is saved as 'wifi_signal_chart.png'.  3. **Detailed Report Generation**: The `generate_wifi_report()` function creates a markdown-formatted report containing:    - A summary table with ranks, SSIDs, signal strengths, and categories (Strong, Good, or Weak).    - Detailed results for each network, including their SSID, signal strength, and category.    - A reference to the visualization image (wifi_signal_chart.png).  4. **Main Execution**: In the main part of the script, it scans for Wi-Fi networks using `scan_wifi()`, displays available networks with their signal strengths, generates a visual representation using `plot_wifi()`, and creates a detailed report using `generate_wifi_report()`. If no networks are found, it informs the user accordingly.  To use this script: 1. Ensure you have Python 3 installed on your system. 2. Install required packages by running `pip install netifaces matplotlib`. 3. Save the script as a .py file (e.g., wifi_analysis.py). 4. Run the script using `python wifi_analysis.py` in your terminal or command prompt.  The output will be: - A visual representation of Wi-Fi networks and their signal strengths saved as 'wifi_signal_chart.png'. - A markdown-formatted report detailing the scan results, saved as 'wifi_report.md' within the specified directory ('wireless_security/wireless_reports'). | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Network_Security/wireless_security/WiFi_Discover/wifi_signal_discovery.py) |
| `Network_Security/wireless_security/Wifi_Attack/wifi_deauth.py` | This Python script conducts a WiFi Deauthentication Attack, sending deauth packets from an AP MAC to a target client or broadcast. It requires root privileges and uses Scapy library for packet manipulation. Input parameters include AP MAC, target MAC (or broadcast), interface, and count of packets. | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Network_Security/wireless_security/Wifi_Attack/wifi_deauth.py) |
| `Network_Security/wireless_security/Wifi_Attack/wifi_jam.py` | This Python script performs a WiFi Beacon Flooding Attack. It generates random SSIDs and BSSIDs to send fake beacon frames, potentially disrupting Wi-Fi networks. Requires root access for interface manipulation. Customizable with `--iface` (interface) and `--count` (number of beacons). | [Link](https://github.com/rgrit/RGRIT.US_CyberTools/blob/main/Network_Security/wireless_security/Wifi_Attack/wifi_jam.py) |
